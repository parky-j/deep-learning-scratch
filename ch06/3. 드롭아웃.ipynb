{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bece99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
    "from common.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e5b2331",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ddc04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오버피팅을 재현하기 위해 학습 데이터 수를 줄임\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542cb56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_dropout = True # False일 경우 드롭아웃을 사용하지 않음.\n",
    "dropout_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "712faf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.300511985307158\n",
      "=== epoch:1, train acc:0.14, test acc:0.1217 ===\n",
      "train loss:2.3023187487177212\n",
      "train loss:2.295939493908679\n",
      "train loss:2.2827151251764577\n",
      "=== epoch:2, train acc:0.14666666666666667, test acc:0.1232 ===\n",
      "train loss:2.2940619598370535\n",
      "train loss:2.2964497007844096\n",
      "train loss:2.289498346007908\n",
      "=== epoch:3, train acc:0.15, test acc:0.1243 ===\n",
      "train loss:2.2981955807930157\n",
      "train loss:2.288182222526382\n",
      "train loss:2.288824425052313\n",
      "=== epoch:4, train acc:0.14666666666666667, test acc:0.1265 ===\n",
      "train loss:2.2795915002810814\n",
      "train loss:2.289819511514242\n",
      "train loss:2.2962582867196137\n",
      "=== epoch:5, train acc:0.15333333333333332, test acc:0.1265 ===\n",
      "train loss:2.3041824316181034\n",
      "train loss:2.292596605096488\n",
      "train loss:2.2851404981555277\n",
      "=== epoch:6, train acc:0.15333333333333332, test acc:0.1273 ===\n",
      "train loss:2.3009858556102993\n",
      "train loss:2.2792028198489134\n",
      "train loss:2.287166039453251\n",
      "=== epoch:7, train acc:0.15333333333333332, test acc:0.1295 ===\n",
      "train loss:2.289023157585248\n",
      "train loss:2.2849163672022352\n",
      "train loss:2.2761564252813304\n",
      "=== epoch:8, train acc:0.16, test acc:0.1304 ===\n",
      "train loss:2.3071226534028484\n",
      "train loss:2.2802572472877043\n",
      "train loss:2.2814127685218324\n",
      "=== epoch:9, train acc:0.16333333333333333, test acc:0.1312 ===\n",
      "train loss:2.284081116798623\n",
      "train loss:2.2938321699859467\n",
      "train loss:2.2750504223266073\n",
      "=== epoch:10, train acc:0.16, test acc:0.1328 ===\n",
      "train loss:2.2921135611409\n",
      "train loss:2.272136966493367\n",
      "train loss:2.2822876008438184\n",
      "=== epoch:11, train acc:0.16, test acc:0.1339 ===\n",
      "train loss:2.2754804634388694\n",
      "train loss:2.285370914609684\n",
      "train loss:2.272635913394241\n",
      "=== epoch:12, train acc:0.16333333333333333, test acc:0.1351 ===\n",
      "train loss:2.278390686786688\n",
      "train loss:2.2958874038708914\n",
      "train loss:2.2744644521184916\n",
      "=== epoch:13, train acc:0.16666666666666666, test acc:0.1359 ===\n",
      "train loss:2.273496172935792\n",
      "train loss:2.276573728191116\n",
      "train loss:2.274152970744557\n",
      "=== epoch:14, train acc:0.16666666666666666, test acc:0.1376 ===\n",
      "train loss:2.2886835517626536\n",
      "train loss:2.295502439031613\n",
      "train loss:2.2818627324142664\n",
      "=== epoch:15, train acc:0.16666666666666666, test acc:0.1384 ===\n",
      "train loss:2.2811435844734653\n",
      "train loss:2.2763094012291307\n",
      "train loss:2.253962147358844\n",
      "=== epoch:16, train acc:0.17, test acc:0.1399 ===\n",
      "train loss:2.2670947720158\n",
      "train loss:2.2935408628174865\n",
      "train loss:2.2607778075817224\n",
      "=== epoch:17, train acc:0.17333333333333334, test acc:0.142 ===\n",
      "train loss:2.2667914875116475\n",
      "train loss:2.2646197152984517\n",
      "train loss:2.278831947304659\n",
      "=== epoch:18, train acc:0.17333333333333334, test acc:0.1437 ===\n",
      "train loss:2.26183365931125\n",
      "train loss:2.2748682073965805\n",
      "train loss:2.268150640616078\n",
      "=== epoch:19, train acc:0.17333333333333334, test acc:0.1442 ===\n",
      "train loss:2.2510324817332554\n",
      "train loss:2.261042273442611\n",
      "train loss:2.2590192469835007\n",
      "=== epoch:20, train acc:0.17333333333333334, test acc:0.1462 ===\n",
      "train loss:2.2635037909870768\n",
      "train loss:2.259873164423243\n",
      "train loss:2.2676874277707912\n",
      "=== epoch:21, train acc:0.17666666666666667, test acc:0.147 ===\n",
      "train loss:2.281446584429158\n",
      "train loss:2.2486460338211414\n",
      "train loss:2.2778968297260183\n",
      "=== epoch:22, train acc:0.17666666666666667, test acc:0.1485 ===\n",
      "train loss:2.283377907661333\n",
      "train loss:2.27228093993005\n",
      "train loss:2.266562677510143\n",
      "=== epoch:23, train acc:0.17666666666666667, test acc:0.1512 ===\n",
      "train loss:2.277095314658706\n",
      "train loss:2.2604007226406297\n",
      "train loss:2.26466358472426\n",
      "=== epoch:24, train acc:0.18, test acc:0.1521 ===\n",
      "train loss:2.2763415793327675\n",
      "train loss:2.2569470233303464\n",
      "train loss:2.2548827466058516\n",
      "=== epoch:25, train acc:0.18666666666666668, test acc:0.154 ===\n",
      "train loss:2.2824824437735574\n",
      "train loss:2.258011188529161\n",
      "train loss:2.253230668330799\n",
      "=== epoch:26, train acc:0.19, test acc:0.1548 ===\n",
      "train loss:2.2794306594504907\n",
      "train loss:2.2576625836101156\n",
      "train loss:2.267319105616098\n",
      "=== epoch:27, train acc:0.19, test acc:0.1563 ===\n",
      "train loss:2.259156615267559\n",
      "train loss:2.2582264974702237\n",
      "train loss:2.25028451191807\n",
      "=== epoch:28, train acc:0.19333333333333333, test acc:0.1583 ===\n",
      "train loss:2.2725710988555257\n",
      "train loss:2.2686382391650586\n",
      "train loss:2.2539273266066937\n",
      "=== epoch:29, train acc:0.19666666666666666, test acc:0.1602 ===\n",
      "train loss:2.2526693987873854\n",
      "train loss:2.2435011593521756\n",
      "train loss:2.263955588736065\n",
      "=== epoch:30, train acc:0.19666666666666666, test acc:0.1647 ===\n",
      "train loss:2.258714841708629\n",
      "train loss:2.267712238522666\n",
      "train loss:2.242480194969415\n",
      "=== epoch:31, train acc:0.2, test acc:0.166 ===\n",
      "train loss:2.234369151259009\n",
      "train loss:2.264818252276816\n",
      "train loss:2.2490321226422796\n",
      "=== epoch:32, train acc:0.19666666666666666, test acc:0.1658 ===\n",
      "train loss:2.2436882467854193\n",
      "train loss:2.254660404339587\n",
      "train loss:2.256271624115138\n",
      "=== epoch:33, train acc:0.2, test acc:0.1663 ===\n",
      "train loss:2.26840097114072\n",
      "train loss:2.253144149219132\n",
      "train loss:2.263009209726473\n",
      "=== epoch:34, train acc:0.2, test acc:0.1696 ===\n",
      "train loss:2.2486895584111504\n",
      "train loss:2.2607953411270123\n",
      "train loss:2.2276334204688815\n",
      "=== epoch:35, train acc:0.20333333333333334, test acc:0.1708 ===\n",
      "train loss:2.2607243686635154\n",
      "train loss:2.2408704273893494\n",
      "train loss:2.240822184266639\n",
      "=== epoch:36, train acc:0.21333333333333335, test acc:0.1732 ===\n",
      "train loss:2.239213420971232\n",
      "train loss:2.2419470272197737\n",
      "train loss:2.255141243147162\n",
      "=== epoch:37, train acc:0.20666666666666667, test acc:0.1744 ===\n",
      "train loss:2.249789262903646\n",
      "train loss:2.26317676109451\n",
      "train loss:2.2338518218994072\n",
      "=== epoch:38, train acc:0.21666666666666667, test acc:0.1764 ===\n",
      "train loss:2.2546522226753964\n",
      "train loss:2.241598423179441\n",
      "train loss:2.2372520645936085\n",
      "=== epoch:39, train acc:0.21666666666666667, test acc:0.178 ===\n",
      "train loss:2.269676462309945\n",
      "train loss:2.2632435930171217\n",
      "train loss:2.243283355376727\n",
      "=== epoch:40, train acc:0.22333333333333333, test acc:0.1809 ===\n",
      "train loss:2.2494595488838653\n",
      "train loss:2.237925504276148\n",
      "train loss:2.2645438945762857\n",
      "=== epoch:41, train acc:0.23, test acc:0.1845 ===\n",
      "train loss:2.238158627222677\n",
      "train loss:2.2379945087157846\n",
      "train loss:2.2466761003261864\n",
      "=== epoch:42, train acc:0.24, test acc:0.1882 ===\n",
      "train loss:2.224486031173954\n",
      "train loss:2.2408686901397443\n",
      "train loss:2.2261486302524527\n",
      "=== epoch:43, train acc:0.23666666666666666, test acc:0.1891 ===\n",
      "train loss:2.2334959940728094\n",
      "train loss:2.2420206469850443\n",
      "train loss:2.2324962657981504\n",
      "=== epoch:44, train acc:0.23666666666666666, test acc:0.1888 ===\n",
      "train loss:2.233006769406888\n",
      "train loss:2.222699488719281\n",
      "train loss:2.232434691500142\n",
      "=== epoch:45, train acc:0.24, test acc:0.1879 ===\n",
      "train loss:2.232509315843986\n",
      "train loss:2.2462922916595676\n",
      "train loss:2.234369909383267\n",
      "=== epoch:46, train acc:0.24, test acc:0.1898 ===\n",
      "train loss:2.2272016753781743\n",
      "train loss:2.2381769645230234\n",
      "train loss:2.2349236035990048\n",
      "=== epoch:47, train acc:0.24, test acc:0.1923 ===\n",
      "train loss:2.2413889815162102\n",
      "train loss:2.221618998504793\n",
      "train loss:2.243196300972132\n",
      "=== epoch:48, train acc:0.24666666666666667, test acc:0.1922 ===\n",
      "train loss:2.204963092476446\n",
      "train loss:2.2323368634808416\n",
      "train loss:2.226070522372653\n",
      "=== epoch:49, train acc:0.24, test acc:0.1916 ===\n",
      "train loss:2.2384845044505854\n",
      "train loss:2.2390935079104044\n",
      "train loss:2.238007349944109\n",
      "=== epoch:50, train acc:0.24, test acc:0.1918 ===\n",
      "train loss:2.2226036958395894\n",
      "train loss:2.2278250107052044\n",
      "train loss:2.2490665676273385\n",
      "=== epoch:51, train acc:0.24333333333333335, test acc:0.194 ===\n",
      "train loss:2.2007357866576576\n",
      "train loss:2.22059804953715\n",
      "train loss:2.185486129725993\n",
      "=== epoch:52, train acc:0.24333333333333335, test acc:0.1936 ===\n",
      "train loss:2.2386449673867603\n",
      "train loss:2.2228213983963077\n",
      "train loss:2.2184831464572623\n",
      "=== epoch:53, train acc:0.24666666666666667, test acc:0.1948 ===\n",
      "train loss:2.2170817131173455\n",
      "train loss:2.2285473991539364\n",
      "train loss:2.215079360422856\n",
      "=== epoch:54, train acc:0.25, test acc:0.1965 ===\n",
      "train loss:2.218461688176457\n",
      "train loss:2.2073495509811893\n",
      "train loss:2.221462283621098\n",
      "=== epoch:55, train acc:0.25333333333333335, test acc:0.1958 ===\n",
      "train loss:2.213234649417605\n",
      "train loss:2.2538432375930655\n",
      "train loss:2.2263548647974996\n",
      "=== epoch:56, train acc:0.25333333333333335, test acc:0.1996 ===\n",
      "train loss:2.225141700448115\n",
      "train loss:2.2139671791198787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.219291895707053\n",
      "=== epoch:57, train acc:0.25333333333333335, test acc:0.2019 ===\n",
      "train loss:2.2077357788217298\n",
      "train loss:2.230538224421745\n",
      "train loss:2.192727928731871\n",
      "=== epoch:58, train acc:0.25333333333333335, test acc:0.2026 ===\n",
      "train loss:2.203551293100098\n",
      "train loss:2.2009282662262053\n",
      "train loss:2.2066553711277104\n",
      "=== epoch:59, train acc:0.25333333333333335, test acc:0.2036 ===\n",
      "train loss:2.1952771215021287\n",
      "train loss:2.222507028275828\n",
      "train loss:2.1761731798958035\n",
      "=== epoch:60, train acc:0.25333333333333335, test acc:0.2042 ===\n",
      "train loss:2.205069697494319\n",
      "train loss:2.202257203328077\n",
      "train loss:2.2071228149616515\n",
      "=== epoch:61, train acc:0.26, test acc:0.2055 ===\n",
      "train loss:2.2042165424553635\n",
      "train loss:2.2014066415755917\n",
      "train loss:2.196806714082755\n",
      "=== epoch:62, train acc:0.25666666666666665, test acc:0.2062 ===\n",
      "train loss:2.203054408275797\n",
      "train loss:2.202974363653609\n",
      "train loss:2.220775147032341\n",
      "=== epoch:63, train acc:0.25, test acc:0.205 ===\n",
      "train loss:2.2140712462632512\n",
      "train loss:2.159452788112249\n",
      "train loss:2.196749021195483\n",
      "=== epoch:64, train acc:0.25333333333333335, test acc:0.2046 ===\n",
      "train loss:2.2101186368791277\n",
      "train loss:2.189288801545717\n",
      "train loss:2.207849131151924\n",
      "=== epoch:65, train acc:0.25333333333333335, test acc:0.2043 ===\n",
      "train loss:2.215674469845463\n",
      "train loss:2.2141815034411487\n",
      "train loss:2.2070232438679374\n",
      "=== epoch:66, train acc:0.25333333333333335, test acc:0.2067 ===\n",
      "train loss:2.2088975941526803\n",
      "train loss:2.213005565424651\n",
      "train loss:2.187865422709943\n",
      "=== epoch:67, train acc:0.25333333333333335, test acc:0.2089 ===\n",
      "train loss:2.1486906660543332\n",
      "train loss:2.2421282107656206\n",
      "train loss:2.194469406104369\n",
      "=== epoch:68, train acc:0.26, test acc:0.2109 ===\n",
      "train loss:2.1713262622645892\n",
      "train loss:2.172519784957605\n",
      "train loss:2.171534047790177\n",
      "=== epoch:69, train acc:0.25333333333333335, test acc:0.2091 ===\n",
      "train loss:2.198335748351096\n",
      "train loss:2.1571793016589615\n",
      "train loss:2.2167859758516633\n",
      "=== epoch:70, train acc:0.25666666666666665, test acc:0.2073 ===\n",
      "train loss:2.2067559118271705\n",
      "train loss:2.153772977502228\n",
      "train loss:2.168126409256251\n",
      "=== epoch:71, train acc:0.25666666666666665, test acc:0.2063 ===\n",
      "train loss:2.185860600450253\n",
      "train loss:2.1835349966152013\n",
      "train loss:2.204706021823043\n",
      "=== epoch:72, train acc:0.25666666666666665, test acc:0.2081 ===\n",
      "train loss:2.2242392562674866\n",
      "train loss:2.2050605627276947\n",
      "train loss:2.185552067978102\n",
      "=== epoch:73, train acc:0.27, test acc:0.2107 ===\n",
      "train loss:2.204154185626219\n",
      "train loss:2.151480057429525\n",
      "train loss:2.177586714917095\n",
      "=== epoch:74, train acc:0.25666666666666665, test acc:0.2113 ===\n",
      "train loss:2.188698229748491\n",
      "train loss:2.183561368301763\n",
      "train loss:2.1853619650537626\n",
      "=== epoch:75, train acc:0.25666666666666665, test acc:0.2134 ===\n",
      "train loss:2.1876509492712812\n",
      "train loss:2.138539322661156\n",
      "train loss:2.1489312975343005\n",
      "=== epoch:76, train acc:0.25333333333333335, test acc:0.21 ===\n",
      "train loss:2.1807978214520745\n",
      "train loss:2.2090105965371483\n",
      "train loss:2.1734432209895944\n",
      "=== epoch:77, train acc:0.26, test acc:0.2141 ===\n",
      "train loss:2.1475196107184558\n",
      "train loss:2.2071269724274116\n",
      "train loss:2.1610239302361345\n",
      "=== epoch:78, train acc:0.25666666666666665, test acc:0.2161 ===\n",
      "train loss:2.129877967843784\n",
      "train loss:2.16081176007499\n",
      "train loss:2.174460579047132\n",
      "=== epoch:79, train acc:0.26666666666666666, test acc:0.2154 ===\n",
      "train loss:2.1665958605715834\n",
      "train loss:2.139250363903475\n",
      "train loss:2.1838337720133634\n",
      "=== epoch:80, train acc:0.26, test acc:0.2151 ===\n",
      "train loss:2.1350945638625407\n",
      "train loss:2.1466636763867344\n",
      "train loss:2.1586657731298553\n",
      "=== epoch:81, train acc:0.25666666666666665, test acc:0.2118 ===\n",
      "train loss:2.11793761714252\n",
      "train loss:2.1586772496457134\n",
      "train loss:2.135383754124929\n",
      "=== epoch:82, train acc:0.25666666666666665, test acc:0.2122 ===\n",
      "train loss:2.1793751642921126\n",
      "train loss:2.146555939673714\n",
      "train loss:2.159721408510989\n",
      "=== epoch:83, train acc:0.26, test acc:0.2138 ===\n",
      "train loss:2.155989793610154\n",
      "train loss:2.1299833935587698\n",
      "train loss:2.144866394104077\n",
      "=== epoch:84, train acc:0.26, test acc:0.2137 ===\n",
      "train loss:2.096514688173053\n",
      "train loss:2.182127637450388\n",
      "train loss:2.0622440370721\n",
      "=== epoch:85, train acc:0.26, test acc:0.2121 ===\n",
      "train loss:2.1289494908134214\n",
      "train loss:2.12640013543013\n",
      "train loss:2.08371990519763\n",
      "=== epoch:86, train acc:0.26, test acc:0.2115 ===\n",
      "train loss:2.1585961139543035\n",
      "train loss:2.188211977963121\n",
      "train loss:2.176154640883487\n",
      "=== epoch:87, train acc:0.26666666666666666, test acc:0.2166 ===\n",
      "train loss:2.136109248631756\n",
      "train loss:2.1227716627329785\n",
      "train loss:2.1831492840744073\n",
      "=== epoch:88, train acc:0.2633333333333333, test acc:0.2192 ===\n",
      "train loss:2.153400242085377\n",
      "train loss:2.011467401460961\n",
      "train loss:2.133975203865593\n",
      "=== epoch:89, train acc:0.2733333333333333, test acc:0.2171 ===\n",
      "train loss:2.1472729469736325\n",
      "train loss:2.126264542405205\n",
      "train loss:2.073157611267335\n",
      "=== epoch:90, train acc:0.2633333333333333, test acc:0.2141 ===\n",
      "train loss:2.1026060951788246\n",
      "train loss:2.11321000824685\n",
      "train loss:2.1413556441919352\n",
      "=== epoch:91, train acc:0.27, test acc:0.2184 ===\n",
      "train loss:2.0821769811319486\n",
      "train loss:2.130660878962311\n",
      "train loss:2.1738346796949544\n",
      "=== epoch:92, train acc:0.2733333333333333, test acc:0.2192 ===\n",
      "train loss:2.0905601468654798\n",
      "train loss:2.144689867959067\n",
      "train loss:2.1702357051086363\n",
      "=== epoch:93, train acc:0.2866666666666667, test acc:0.2232 ===\n",
      "train loss:2.115450706848452\n",
      "train loss:2.0747642938153064\n",
      "train loss:2.1710020738850675\n",
      "=== epoch:94, train acc:0.2866666666666667, test acc:0.2232 ===\n",
      "train loss:2.135096510141434\n",
      "train loss:2.1456836099963876\n",
      "train loss:2.1172264527986555\n",
      "=== epoch:95, train acc:0.2866666666666667, test acc:0.2286 ===\n",
      "train loss:2.1387311387227657\n",
      "train loss:2.091017883950807\n",
      "train loss:2.091846131854046\n",
      "=== epoch:96, train acc:0.29333333333333333, test acc:0.2287 ===\n",
      "train loss:2.09013688205053\n",
      "train loss:2.061060505844886\n",
      "train loss:2.1060109274660146\n",
      "=== epoch:97, train acc:0.29333333333333333, test acc:0.2274 ===\n",
      "train loss:2.11641914798484\n",
      "train loss:2.114269725372398\n",
      "train loss:2.166139620830273\n",
      "=== epoch:98, train acc:0.2966666666666667, test acc:0.2296 ===\n",
      "train loss:2.153853777804381\n",
      "train loss:2.0527086173489395\n",
      "train loss:2.090226934907711\n",
      "=== epoch:99, train acc:0.29333333333333333, test acc:0.231 ===\n",
      "train loss:2.106557872725915\n",
      "train loss:2.1343098551608715\n",
      "train loss:2.1178682020779878\n",
      "=== epoch:100, train acc:0.2966666666666667, test acc:0.2349 ===\n",
      "train loss:2.110706623051342\n",
      "train loss:2.0447199927871424\n",
      "train loss:2.0260024270695633\n",
      "=== epoch:101, train acc:0.2966666666666667, test acc:0.2356 ===\n",
      "train loss:1.99810751237661\n",
      "train loss:2.0833009731303744\n",
      "train loss:2.071847258006662\n",
      "=== epoch:102, train acc:0.2966666666666667, test acc:0.2333 ===\n",
      "train loss:2.09203716901496\n",
      "train loss:2.0858912094251276\n",
      "train loss:2.0442977213082743\n",
      "=== epoch:103, train acc:0.29, test acc:0.2335 ===\n",
      "train loss:2.055643204785995\n",
      "train loss:2.0878255561994066\n",
      "train loss:2.1591954746449233\n",
      "=== epoch:104, train acc:0.29333333333333333, test acc:0.2362 ===\n",
      "train loss:2.1121413577031767\n",
      "train loss:2.082442187804261\n",
      "train loss:2.080738433559118\n",
      "=== epoch:105, train acc:0.2966666666666667, test acc:0.2401 ===\n",
      "train loss:2.119471518270193\n",
      "train loss:2.017708204764416\n",
      "train loss:2.0592669900767255\n",
      "=== epoch:106, train acc:0.29333333333333333, test acc:0.2373 ===\n",
      "train loss:2.0395413240054237\n",
      "train loss:2.1220887463595295\n",
      "train loss:2.0597678502365824\n",
      "=== epoch:107, train acc:0.29, test acc:0.2359 ===\n",
      "train loss:1.9529190988408303\n",
      "train loss:2.182039784771458\n",
      "train loss:2.0598284650169476\n",
      "=== epoch:108, train acc:0.2833333333333333, test acc:0.2344 ===\n",
      "train loss:2.062415140076509\n",
      "train loss:1.8838062548132737\n",
      "train loss:2.057543773188746\n",
      "=== epoch:109, train acc:0.2866666666666667, test acc:0.2344 ===\n",
      "train loss:1.9636387151393258\n",
      "train loss:2.071381282436963\n",
      "train loss:2.0289318780146886\n",
      "=== epoch:110, train acc:0.27666666666666667, test acc:0.2319 ===\n",
      "train loss:2.095085016111792\n",
      "train loss:2.083161932116312\n",
      "train loss:2.094919687091317\n",
      "=== epoch:111, train acc:0.28, test acc:0.2342 ===\n",
      "train loss:2.0035400290364653\n",
      "train loss:2.094281908577836\n",
      "train loss:2.0132896108501313\n",
      "=== epoch:112, train acc:0.2866666666666667, test acc:0.2358 ===\n",
      "train loss:2.0285456089257856\n",
      "train loss:2.013110427078654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.071197329717445\n",
      "=== epoch:113, train acc:0.2866666666666667, test acc:0.2353 ===\n",
      "train loss:2.056955400032349\n",
      "train loss:2.0335372172853634\n",
      "train loss:2.022430157606279\n",
      "=== epoch:114, train acc:0.29, test acc:0.2373 ===\n",
      "train loss:1.9915247064558637\n",
      "train loss:2.029458820263332\n",
      "train loss:2.011411698535225\n",
      "=== epoch:115, train acc:0.2833333333333333, test acc:0.2361 ===\n",
      "train loss:2.024764820984546\n",
      "train loss:2.018274032190023\n",
      "train loss:1.9929865423050608\n",
      "=== epoch:116, train acc:0.2833333333333333, test acc:0.2372 ===\n",
      "train loss:2.1055500565215026\n",
      "train loss:2.0220586725088303\n",
      "train loss:2.012873334380226\n",
      "=== epoch:117, train acc:0.2866666666666667, test acc:0.2366 ===\n",
      "train loss:1.9831330233418338\n",
      "train loss:2.080765698078416\n",
      "train loss:2.031428874779776\n",
      "=== epoch:118, train acc:0.29, test acc:0.2379 ===\n",
      "train loss:2.110955347694236\n",
      "train loss:2.0372822917821694\n",
      "train loss:1.9791826975858522\n",
      "=== epoch:119, train acc:0.2866666666666667, test acc:0.2368 ===\n",
      "train loss:1.9588166917091372\n",
      "train loss:2.0016444677957783\n",
      "train loss:2.0275463647194756\n",
      "=== epoch:120, train acc:0.2866666666666667, test acc:0.2381 ===\n",
      "train loss:1.9921537613005356\n",
      "train loss:2.0268763808058305\n",
      "train loss:2.030872720572845\n",
      "=== epoch:121, train acc:0.29333333333333333, test acc:0.238 ===\n",
      "train loss:2.1120148827988583\n",
      "train loss:2.005365090157278\n",
      "train loss:1.9855246041549883\n",
      "=== epoch:122, train acc:0.29333333333333333, test acc:0.2395 ===\n",
      "train loss:1.96262056717738\n",
      "train loss:1.8684194201482816\n",
      "train loss:1.990683574981704\n",
      "=== epoch:123, train acc:0.2966666666666667, test acc:0.2384 ===\n",
      "train loss:2.044826098429297\n",
      "train loss:1.9970307543753245\n",
      "train loss:1.9120029070537639\n",
      "=== epoch:124, train acc:0.2966666666666667, test acc:0.239 ===\n",
      "train loss:2.046337092915988\n",
      "train loss:1.927787650902614\n",
      "train loss:1.9968440544317414\n",
      "=== epoch:125, train acc:0.2966666666666667, test acc:0.241 ===\n",
      "train loss:2.027741905398593\n",
      "train loss:2.0635483044036236\n",
      "train loss:1.9489396462945927\n",
      "=== epoch:126, train acc:0.30333333333333334, test acc:0.246 ===\n",
      "train loss:2.030966693999552\n",
      "train loss:1.936122511740799\n",
      "train loss:2.020950046502104\n",
      "=== epoch:127, train acc:0.31, test acc:0.2466 ===\n",
      "train loss:1.972715604307134\n",
      "train loss:1.9531886146591353\n",
      "train loss:2.0416098535864897\n",
      "=== epoch:128, train acc:0.31, test acc:0.2489 ===\n",
      "train loss:1.9500845400823843\n",
      "train loss:2.0079327944091174\n",
      "train loss:2.006641270630963\n",
      "=== epoch:129, train acc:0.32, test acc:0.2519 ===\n",
      "train loss:1.9550238058537275\n",
      "train loss:1.9053027816849764\n",
      "train loss:1.9236770094127105\n",
      "=== epoch:130, train acc:0.32, test acc:0.252 ===\n",
      "train loss:2.015017694735921\n",
      "train loss:2.0237031000605428\n",
      "train loss:2.046784622882728\n",
      "=== epoch:131, train acc:0.33, test acc:0.256 ===\n",
      "train loss:1.9341402213024173\n",
      "train loss:1.8854099528724353\n",
      "train loss:2.053627950576153\n",
      "=== epoch:132, train acc:0.32666666666666666, test acc:0.2567 ===\n",
      "train loss:2.003287255780981\n",
      "train loss:1.9870203319198967\n",
      "train loss:1.925152070970671\n",
      "=== epoch:133, train acc:0.33, test acc:0.2573 ===\n",
      "train loss:1.942896449161451\n",
      "train loss:2.0686511794677274\n",
      "train loss:1.9031191308489006\n",
      "=== epoch:134, train acc:0.3333333333333333, test acc:0.2603 ===\n",
      "train loss:1.9344031343903547\n",
      "train loss:1.9757486289290085\n",
      "train loss:2.0022205185991258\n",
      "=== epoch:135, train acc:0.33666666666666667, test acc:0.2621 ===\n",
      "train loss:2.0156416665599903\n",
      "train loss:1.943271112359713\n",
      "train loss:1.9663030137884892\n",
      "=== epoch:136, train acc:0.34, test acc:0.2637 ===\n",
      "train loss:2.025602203550176\n",
      "train loss:2.0076539976668495\n",
      "train loss:1.9661106874036474\n",
      "=== epoch:137, train acc:0.3433333333333333, test acc:0.2666 ===\n",
      "train loss:1.9686631889467807\n",
      "train loss:1.9832472060563173\n",
      "train loss:1.9402475696656607\n",
      "=== epoch:138, train acc:0.3466666666666667, test acc:0.2662 ===\n",
      "train loss:2.062934246538482\n",
      "train loss:1.8767184042711862\n",
      "train loss:1.941864938154302\n",
      "=== epoch:139, train acc:0.3466666666666667, test acc:0.268 ===\n",
      "train loss:1.9895285653435117\n",
      "train loss:1.862056460154264\n",
      "train loss:1.8819511324816818\n",
      "=== epoch:140, train acc:0.35, test acc:0.2657 ===\n",
      "train loss:1.9572685998608592\n",
      "train loss:1.9594354703614298\n",
      "train loss:1.98320346202922\n",
      "=== epoch:141, train acc:0.35, test acc:0.2674 ===\n",
      "train loss:1.862006715331718\n",
      "train loss:2.008452477835843\n",
      "train loss:1.9592519668580934\n",
      "=== epoch:142, train acc:0.3466666666666667, test acc:0.2689 ===\n",
      "train loss:1.931844469444366\n",
      "train loss:1.9701662849956685\n",
      "train loss:1.8686935591352292\n",
      "=== epoch:143, train acc:0.35333333333333333, test acc:0.2709 ===\n",
      "train loss:1.9091377815690687\n",
      "train loss:1.9250074540057591\n",
      "train loss:1.9239240101444517\n",
      "=== epoch:144, train acc:0.35333333333333333, test acc:0.2695 ===\n",
      "train loss:1.917726981040965\n",
      "train loss:1.9997164909334146\n",
      "train loss:1.9217444898034548\n",
      "=== epoch:145, train acc:0.3566666666666667, test acc:0.2718 ===\n",
      "train loss:1.9166603746073252\n",
      "train loss:1.8849721604394543\n",
      "train loss:1.8288409713319111\n",
      "=== epoch:146, train acc:0.35, test acc:0.2704 ===\n",
      "train loss:1.9369896114219403\n",
      "train loss:1.8663162784822815\n",
      "train loss:1.8685779974695746\n",
      "=== epoch:147, train acc:0.35, test acc:0.27 ===\n",
      "train loss:1.897275780326967\n",
      "train loss:1.871382203056723\n",
      "train loss:1.9129309967317334\n",
      "=== epoch:148, train acc:0.35, test acc:0.2684 ===\n",
      "train loss:1.7862506435904675\n",
      "train loss:1.8569996638778536\n",
      "train loss:1.886598287600766\n",
      "=== epoch:149, train acc:0.3466666666666667, test acc:0.2686 ===\n",
      "train loss:1.9594205190744527\n",
      "train loss:1.7789606807091867\n",
      "train loss:1.844637445894373\n",
      "=== epoch:150, train acc:0.35333333333333333, test acc:0.2687 ===\n",
      "train loss:1.949537530410477\n",
      "train loss:1.9136358071165775\n",
      "train loss:1.9063511336106587\n",
      "=== epoch:151, train acc:0.35333333333333333, test acc:0.272 ===\n",
      "train loss:1.8875861855981844\n",
      "train loss:1.9088721890227236\n",
      "train loss:1.9140917134346298\n",
      "=== epoch:152, train acc:0.36333333333333334, test acc:0.2776 ===\n",
      "train loss:1.8537815398994923\n",
      "train loss:1.9673175269557777\n",
      "train loss:1.9188226581240522\n",
      "=== epoch:153, train acc:0.36, test acc:0.2778 ===\n",
      "train loss:1.810947786280032\n",
      "train loss:1.9378587243167957\n",
      "train loss:1.9384328277005716\n",
      "=== epoch:154, train acc:0.37, test acc:0.2791 ===\n",
      "train loss:1.8188938927528289\n",
      "train loss:1.987485356720591\n",
      "train loss:1.9796932010366346\n",
      "=== epoch:155, train acc:0.37666666666666665, test acc:0.2822 ===\n",
      "train loss:1.92572941373867\n",
      "train loss:1.7717573197565653\n",
      "train loss:1.8138221748407413\n",
      "=== epoch:156, train acc:0.37, test acc:0.281 ===\n",
      "train loss:1.9468659035941545\n",
      "train loss:1.8903463095978166\n",
      "train loss:1.8681900411332284\n",
      "=== epoch:157, train acc:0.36666666666666664, test acc:0.2823 ===\n",
      "train loss:1.8027104151996358\n",
      "train loss:1.8060954007247707\n",
      "train loss:1.8246274514118535\n",
      "=== epoch:158, train acc:0.36333333333333334, test acc:0.2831 ===\n",
      "train loss:1.8841194145024736\n",
      "train loss:1.8553866847397362\n",
      "train loss:1.8801451519716215\n",
      "=== epoch:159, train acc:0.37333333333333335, test acc:0.2842 ===\n",
      "train loss:1.9662583416805808\n",
      "train loss:1.888222343601694\n",
      "train loss:1.9140503815696541\n",
      "=== epoch:160, train acc:0.36666666666666664, test acc:0.2862 ===\n",
      "train loss:1.8146130758114543\n",
      "train loss:1.8251279757317278\n",
      "train loss:1.5625218193026358\n",
      "=== epoch:161, train acc:0.36666666666666664, test acc:0.2837 ===\n",
      "train loss:1.8923466972802623\n",
      "train loss:1.8440854838368483\n",
      "train loss:1.9172762308627886\n",
      "=== epoch:162, train acc:0.37333333333333335, test acc:0.2876 ===\n",
      "train loss:1.7338701822577025\n",
      "train loss:1.8916429632449125\n",
      "train loss:1.9312518616012049\n",
      "=== epoch:163, train acc:0.36666666666666664, test acc:0.2854 ===\n",
      "train loss:1.8633850238053262\n",
      "train loss:1.9318736245849584\n",
      "train loss:1.8928680838012886\n",
      "=== epoch:164, train acc:0.38, test acc:0.2927 ===\n",
      "train loss:1.7711753630401685\n",
      "train loss:1.8407336623560855\n",
      "train loss:1.8889184940976218\n",
      "=== epoch:165, train acc:0.38, test acc:0.2924 ===\n",
      "train loss:1.7988814249934224\n",
      "train loss:1.8881800479692652\n",
      "train loss:1.8483169923553\n",
      "=== epoch:166, train acc:0.38, test acc:0.2937 ===\n",
      "train loss:1.8542564250772076\n",
      "train loss:1.822897661708402\n",
      "train loss:1.8584005120673501\n",
      "=== epoch:167, train acc:0.38666666666666666, test acc:0.2977 ===\n",
      "train loss:1.8577100137916853\n",
      "train loss:1.8735541858272888\n",
      "train loss:1.816742459643971\n",
      "=== epoch:168, train acc:0.39, test acc:0.2975 ===\n",
      "train loss:1.8914196110792136\n",
      "train loss:1.8163361401661395\n",
      "train loss:1.7688855524773606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:169, train acc:0.39, test acc:0.3004 ===\n",
      "train loss:1.924335175596639\n",
      "train loss:1.9205007091547186\n",
      "train loss:1.7867049893106022\n",
      "=== epoch:170, train acc:0.39, test acc:0.3059 ===\n",
      "train loss:1.9340616413786398\n",
      "train loss:1.8943209166034867\n",
      "train loss:1.7280593133218576\n",
      "=== epoch:171, train acc:0.3933333333333333, test acc:0.3093 ===\n",
      "train loss:1.8169394817084785\n",
      "train loss:1.7411197383140753\n",
      "train loss:1.8491685474575228\n",
      "=== epoch:172, train acc:0.39666666666666667, test acc:0.3127 ===\n",
      "train loss:1.8209580649328878\n",
      "train loss:1.930375631113845\n",
      "train loss:1.9163296479963245\n",
      "=== epoch:173, train acc:0.41333333333333333, test acc:0.3168 ===\n",
      "train loss:1.8684874432357825\n",
      "train loss:1.851941112967017\n",
      "train loss:1.8727822578002788\n",
      "=== epoch:174, train acc:0.41333333333333333, test acc:0.3222 ===\n",
      "train loss:1.639148197780376\n",
      "train loss:1.9391967085537538\n",
      "train loss:1.8471589533407486\n",
      "=== epoch:175, train acc:0.4266666666666667, test acc:0.3192 ===\n",
      "train loss:1.7580447940804909\n",
      "train loss:1.8028571480518396\n",
      "train loss:1.7080649966086003\n",
      "=== epoch:176, train acc:0.42, test acc:0.3255 ===\n",
      "train loss:1.9123271562044097\n",
      "train loss:1.6972169007177373\n",
      "train loss:1.7775973188574192\n",
      "=== epoch:177, train acc:0.43, test acc:0.3287 ===\n",
      "train loss:1.9254821837296519\n",
      "train loss:1.6793584836807494\n",
      "train loss:1.8442771996594942\n",
      "=== epoch:178, train acc:0.43333333333333335, test acc:0.3322 ===\n",
      "train loss:1.9183591449517214\n",
      "train loss:1.672472327952558\n",
      "train loss:1.8108267055092826\n",
      "=== epoch:179, train acc:0.43333333333333335, test acc:0.3378 ===\n",
      "train loss:1.788518219381196\n",
      "train loss:1.8019322811123408\n",
      "train loss:1.7929264646014191\n",
      "=== epoch:180, train acc:0.43333333333333335, test acc:0.3453 ===\n",
      "train loss:1.7241996569926412\n",
      "train loss:1.731740637839186\n",
      "train loss:1.789229742822484\n",
      "=== epoch:181, train acc:0.43666666666666665, test acc:0.3447 ===\n",
      "train loss:1.7916807136662325\n",
      "train loss:1.8576395259721443\n",
      "train loss:1.7499994385811954\n",
      "=== epoch:182, train acc:0.44333333333333336, test acc:0.3436 ===\n",
      "train loss:1.751258181164254\n",
      "train loss:1.8214945811984864\n",
      "train loss:1.9237619372187353\n",
      "=== epoch:183, train acc:0.44666666666666666, test acc:0.3516 ===\n",
      "train loss:1.7316859400717044\n",
      "train loss:1.6699925272005773\n",
      "train loss:1.7586365070908343\n",
      "=== epoch:184, train acc:0.45, test acc:0.3536 ===\n",
      "train loss:1.811877767099977\n",
      "train loss:1.851845742009121\n",
      "train loss:1.7579987326939663\n",
      "=== epoch:185, train acc:0.4533333333333333, test acc:0.3566 ===\n",
      "train loss:1.789958979600914\n",
      "train loss:1.776872180949394\n",
      "train loss:1.9159918191613823\n",
      "=== epoch:186, train acc:0.45666666666666667, test acc:0.3586 ===\n",
      "train loss:1.7733118257155807\n",
      "train loss:1.8101592777478308\n",
      "train loss:1.8752090120435878\n",
      "=== epoch:187, train acc:0.4533333333333333, test acc:0.3581 ===\n",
      "train loss:1.7418556371191725\n",
      "train loss:1.8278343368538401\n",
      "train loss:1.6360627038433575\n",
      "=== epoch:188, train acc:0.45, test acc:0.3609 ===\n",
      "train loss:1.8610050367533089\n",
      "train loss:2.028993002781561\n",
      "train loss:1.868185278801245\n",
      "=== epoch:189, train acc:0.4666666666666667, test acc:0.37 ===\n",
      "train loss:1.894394551854126\n",
      "train loss:1.74575012616158\n",
      "train loss:1.777842961716876\n",
      "=== epoch:190, train acc:0.47, test acc:0.3717 ===\n",
      "train loss:1.7682161879814844\n",
      "train loss:1.8810281308328818\n",
      "train loss:1.846908945628322\n",
      "=== epoch:191, train acc:0.48333333333333334, test acc:0.3791 ===\n",
      "train loss:1.7936902699946344\n",
      "train loss:1.823839027187457\n",
      "train loss:1.8590754195131307\n",
      "=== epoch:192, train acc:0.48333333333333334, test acc:0.381 ===\n",
      "train loss:1.7877519662461023\n",
      "train loss:1.8690914835320882\n",
      "train loss:1.8333849190906242\n",
      "=== epoch:193, train acc:0.48, test acc:0.3824 ===\n",
      "train loss:1.7504553872272515\n",
      "train loss:1.8070163931213046\n",
      "train loss:1.7151822273700583\n",
      "=== epoch:194, train acc:0.48333333333333334, test acc:0.3814 ===\n",
      "train loss:1.7043185199742712\n",
      "train loss:1.7611283179407706\n",
      "train loss:1.8069670193678875\n",
      "=== epoch:195, train acc:0.48, test acc:0.3778 ===\n",
      "train loss:1.685804385540713\n",
      "train loss:1.8161541370010605\n",
      "train loss:1.7167747304973249\n",
      "=== epoch:196, train acc:0.48, test acc:0.3764 ===\n",
      "train loss:1.6896245040240303\n",
      "train loss:1.7984167873846002\n",
      "train loss:1.7369480852411554\n",
      "=== epoch:197, train acc:0.4766666666666667, test acc:0.3739 ===\n",
      "train loss:1.6921221229003758\n",
      "train loss:1.756773051520791\n",
      "train loss:1.5577982409074114\n",
      "=== epoch:198, train acc:0.4766666666666667, test acc:0.3742 ===\n",
      "train loss:1.7880118722291658\n",
      "train loss:1.6361333698596656\n",
      "train loss:1.7742151468175933\n",
      "=== epoch:199, train acc:0.48333333333333334, test acc:0.3757 ===\n",
      "train loss:1.7475082891157612\n",
      "train loss:1.8320069062119826\n",
      "train loss:1.791560236900327\n",
      "=== epoch:200, train acc:0.5, test acc:0.3824 ===\n",
      "train loss:1.80610312982969\n",
      "train loss:1.949153241314556\n",
      "train loss:1.701675329912506\n",
      "=== epoch:201, train acc:0.51, test acc:0.3922 ===\n",
      "train loss:1.732858921143587\n",
      "train loss:1.7200662837300689\n",
      "train loss:1.8198973745336784\n",
      "=== epoch:202, train acc:0.5066666666666667, test acc:0.3894 ===\n",
      "train loss:1.7439618581339902\n",
      "train loss:1.609324442111683\n",
      "train loss:1.724272904671408\n",
      "=== epoch:203, train acc:0.49333333333333335, test acc:0.3829 ===\n",
      "train loss:1.7574007386633448\n",
      "train loss:1.6093227282047697\n",
      "train loss:1.7044693697155773\n",
      "=== epoch:204, train acc:0.49333333333333335, test acc:0.3839 ===\n",
      "train loss:1.663729212172253\n",
      "train loss:1.4911170564124487\n",
      "train loss:1.7410330647793801\n",
      "=== epoch:205, train acc:0.4866666666666667, test acc:0.385 ===\n",
      "train loss:1.7584148890576248\n",
      "train loss:1.8407829162579394\n",
      "train loss:1.8222083951975827\n",
      "=== epoch:206, train acc:0.5, test acc:0.392 ===\n",
      "train loss:1.8285442951537436\n",
      "train loss:1.8247617387040875\n",
      "train loss:1.8288048591905226\n",
      "=== epoch:207, train acc:0.5166666666666667, test acc:0.3962 ===\n",
      "train loss:1.6358633366796298\n",
      "train loss:1.7371447811728542\n",
      "train loss:1.7044685950197738\n",
      "=== epoch:208, train acc:0.5066666666666667, test acc:0.3947 ===\n",
      "train loss:1.7475036990807908\n",
      "train loss:1.6784974484733717\n",
      "train loss:1.6624870314876556\n",
      "=== epoch:209, train acc:0.5033333333333333, test acc:0.3938 ===\n",
      "train loss:1.7238720787398094\n",
      "train loss:1.7127832130547092\n",
      "train loss:1.8810261818287979\n",
      "=== epoch:210, train acc:0.5033333333333333, test acc:0.392 ===\n",
      "train loss:1.746721290502839\n",
      "train loss:1.7144895070379114\n",
      "train loss:1.6866365059020625\n",
      "=== epoch:211, train acc:0.5033333333333333, test acc:0.3969 ===\n",
      "train loss:1.7366987533895661\n",
      "train loss:1.6705855107158216\n",
      "train loss:1.6435323099622723\n",
      "=== epoch:212, train acc:0.5066666666666667, test acc:0.3961 ===\n",
      "train loss:1.8499133807264458\n",
      "train loss:1.687919955986932\n",
      "train loss:1.7445205240551636\n",
      "=== epoch:213, train acc:0.5066666666666667, test acc:0.4033 ===\n",
      "train loss:1.7017498920606502\n",
      "train loss:1.6546982111901736\n",
      "train loss:1.7115465833745112\n",
      "=== epoch:214, train acc:0.51, test acc:0.4043 ===\n",
      "train loss:1.6610967090806334\n",
      "train loss:1.6864689761725282\n",
      "train loss:1.5386696424843507\n",
      "=== epoch:215, train acc:0.5133333333333333, test acc:0.4085 ===\n",
      "train loss:1.7618746364494664\n",
      "train loss:1.767234774526389\n",
      "train loss:1.7507239453651056\n",
      "=== epoch:216, train acc:0.5366666666666666, test acc:0.4185 ===\n",
      "train loss:1.6167552557680545\n",
      "train loss:1.788427817489386\n",
      "train loss:1.636020474213605\n",
      "=== epoch:217, train acc:0.5366666666666666, test acc:0.4172 ===\n",
      "train loss:1.7259254255987324\n",
      "train loss:1.7155322921970366\n",
      "train loss:1.574667545364829\n",
      "=== epoch:218, train acc:0.5433333333333333, test acc:0.4203 ===\n",
      "train loss:1.736043386419488\n",
      "train loss:1.6008988777866193\n",
      "train loss:1.7530505879593037\n",
      "=== epoch:219, train acc:0.55, test acc:0.424 ===\n",
      "train loss:1.7738943888315564\n",
      "train loss:1.6686101551869916\n",
      "train loss:1.5558887145776001\n",
      "=== epoch:220, train acc:0.5466666666666666, test acc:0.4279 ===\n",
      "train loss:1.6297594460283378\n",
      "train loss:1.7462788031343206\n",
      "train loss:1.6438098168261766\n",
      "=== epoch:221, train acc:0.5466666666666666, test acc:0.4293 ===\n",
      "train loss:1.7232222575534775\n",
      "train loss:1.6813711296859932\n",
      "train loss:1.6044231557640678\n",
      "=== epoch:222, train acc:0.55, test acc:0.4309 ===\n",
      "train loss:1.7346074187100868\n",
      "train loss:1.7150900014044734\n",
      "train loss:1.8043617464316493\n",
      "=== epoch:223, train acc:0.55, test acc:0.43 ===\n",
      "train loss:1.7013020797640674\n",
      "train loss:1.6969920892074475\n",
      "train loss:1.7108926412872594\n",
      "=== epoch:224, train acc:0.5533333333333333, test acc:0.4363 ===\n",
      "train loss:1.644842672641168\n",
      "train loss:1.7115611145589233\n",
      "train loss:1.787429815625971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:225, train acc:0.5533333333333333, test acc:0.4437 ===\n",
      "train loss:1.7096425724585549\n",
      "train loss:1.6669410600505123\n",
      "train loss:1.6148231969738134\n",
      "=== epoch:226, train acc:0.5466666666666666, test acc:0.4403 ===\n",
      "train loss:1.7242367985816498\n",
      "train loss:1.6146283103519656\n",
      "train loss:1.5922640375860713\n",
      "=== epoch:227, train acc:0.55, test acc:0.4442 ===\n",
      "train loss:1.5866201255070647\n",
      "train loss:1.6312439826463438\n",
      "train loss:1.6731005422855691\n",
      "=== epoch:228, train acc:0.5466666666666666, test acc:0.4432 ===\n",
      "train loss:1.6941541572900587\n",
      "train loss:1.6573282952885366\n",
      "train loss:1.739189942016408\n",
      "=== epoch:229, train acc:0.5566666666666666, test acc:0.4451 ===\n",
      "train loss:1.5358270733888764\n",
      "train loss:1.5995705869812573\n",
      "train loss:1.6301936074630161\n",
      "=== epoch:230, train acc:0.5466666666666666, test acc:0.4384 ===\n",
      "train loss:1.6844133227660592\n",
      "train loss:1.722617643133963\n",
      "train loss:1.8222867125075597\n",
      "=== epoch:231, train acc:0.5466666666666666, test acc:0.4434 ===\n",
      "train loss:1.5343502259971493\n",
      "train loss:1.7645893632447984\n",
      "train loss:1.616592701520788\n",
      "=== epoch:232, train acc:0.5566666666666666, test acc:0.4485 ===\n",
      "train loss:1.5554246993101597\n",
      "train loss:1.7428464795680956\n",
      "train loss:1.7758177334085408\n",
      "=== epoch:233, train acc:0.55, test acc:0.4477 ===\n",
      "train loss:1.5991564696653249\n",
      "train loss:1.8252884801135558\n",
      "train loss:1.6167867199298653\n",
      "=== epoch:234, train acc:0.57, test acc:0.4615 ===\n",
      "train loss:1.8188645063933822\n",
      "train loss:1.625268763461463\n",
      "train loss:1.6063705893008844\n",
      "=== epoch:235, train acc:0.5666666666666667, test acc:0.4567 ===\n",
      "train loss:1.6772867118015833\n",
      "train loss:1.688575145282083\n",
      "train loss:1.736947928507674\n",
      "=== epoch:236, train acc:0.57, test acc:0.4586 ===\n",
      "train loss:1.7700629621663753\n",
      "train loss:1.7574038555154832\n",
      "train loss:1.6779179098217822\n",
      "=== epoch:237, train acc:0.57, test acc:0.4614 ===\n",
      "train loss:1.5796879731425149\n",
      "train loss:1.5461874283715116\n",
      "train loss:1.725932156313101\n",
      "=== epoch:238, train acc:0.5733333333333334, test acc:0.471 ===\n",
      "train loss:1.6401380625843778\n",
      "train loss:1.6002776221652721\n",
      "train loss:1.6513674043004059\n",
      "=== epoch:239, train acc:0.5733333333333334, test acc:0.4719 ===\n",
      "train loss:1.7698823847997986\n",
      "train loss:1.7234978531900098\n",
      "train loss:1.6132725761994466\n",
      "=== epoch:240, train acc:0.5833333333333334, test acc:0.479 ===\n",
      "train loss:1.703261952525154\n",
      "train loss:1.7157382842046047\n",
      "train loss:1.5369230692191933\n",
      "=== epoch:241, train acc:0.6, test acc:0.4828 ===\n",
      "train loss:1.5809578288789052\n",
      "train loss:1.613571191169155\n",
      "train loss:1.649864650334929\n",
      "=== epoch:242, train acc:0.5966666666666667, test acc:0.4864 ===\n",
      "train loss:1.6673612146412944\n",
      "train loss:1.6408870737637284\n",
      "train loss:1.7623638781659856\n",
      "=== epoch:243, train acc:0.6, test acc:0.4863 ===\n",
      "train loss:1.6314469390270272\n",
      "train loss:1.5806683485947728\n",
      "train loss:1.5591095488154831\n",
      "=== epoch:244, train acc:0.5966666666666667, test acc:0.4884 ===\n",
      "train loss:1.5651030607961116\n",
      "train loss:1.6097670441763858\n",
      "train loss:1.5767546571199156\n",
      "=== epoch:245, train acc:0.6, test acc:0.4884 ===\n",
      "train loss:1.446904891255107\n",
      "train loss:1.6477578025940642\n",
      "train loss:1.44353823518159\n",
      "=== epoch:246, train acc:0.5933333333333334, test acc:0.4854 ===\n",
      "train loss:1.5893244794393495\n",
      "train loss:1.52333365384961\n",
      "train loss:1.7915357910108745\n",
      "=== epoch:247, train acc:0.6033333333333334, test acc:0.4864 ===\n",
      "train loss:1.3294017936981448\n",
      "train loss:1.7115653973098057\n",
      "train loss:1.6041515407814904\n",
      "=== epoch:248, train acc:0.6066666666666667, test acc:0.4893 ===\n",
      "train loss:1.5535481500104518\n",
      "train loss:1.5932530655964101\n",
      "train loss:1.595383797274071\n",
      "=== epoch:249, train acc:0.6066666666666667, test acc:0.4919 ===\n",
      "train loss:1.6936353758748979\n",
      "train loss:1.5902717632730186\n",
      "train loss:1.5422573069917873\n",
      "=== epoch:250, train acc:0.6066666666666667, test acc:0.4934 ===\n",
      "train loss:1.5650507239020903\n",
      "train loss:1.6579261692641287\n",
      "train loss:1.7530997747170611\n",
      "=== epoch:251, train acc:0.6066666666666667, test acc:0.4937 ===\n",
      "train loss:1.6769311898575743\n",
      "train loss:1.5932241598087142\n",
      "train loss:1.6627974511456385\n",
      "=== epoch:252, train acc:0.61, test acc:0.493 ===\n",
      "train loss:1.831855276499391\n",
      "train loss:1.504581759854702\n",
      "train loss:1.5694082486851033\n",
      "=== epoch:253, train acc:0.6066666666666667, test acc:0.4919 ===\n",
      "train loss:1.6711578116538166\n",
      "train loss:1.5204001413253154\n",
      "train loss:1.5878222610060475\n",
      "=== epoch:254, train acc:0.61, test acc:0.4915 ===\n",
      "train loss:1.6265820975659937\n",
      "train loss:1.506570031207557\n",
      "train loss:1.624635503824761\n",
      "=== epoch:255, train acc:0.6033333333333334, test acc:0.4928 ===\n",
      "train loss:1.6461686927200176\n",
      "train loss:1.6289045772742134\n",
      "train loss:1.5050837741345489\n",
      "=== epoch:256, train acc:0.61, test acc:0.5032 ===\n",
      "train loss:1.4308028794240482\n",
      "train loss:1.5851282254106835\n",
      "train loss:1.5924983540739857\n",
      "=== epoch:257, train acc:0.61, test acc:0.5029 ===\n",
      "train loss:1.531100918518414\n",
      "train loss:1.5955078984168247\n",
      "train loss:1.4794218638198045\n",
      "=== epoch:258, train acc:0.6066666666666667, test acc:0.5008 ===\n",
      "train loss:1.6557566299174953\n",
      "train loss:1.5205996217683129\n",
      "train loss:1.4426471820548428\n",
      "=== epoch:259, train acc:0.61, test acc:0.503 ===\n",
      "train loss:1.592908540810847\n",
      "train loss:1.7258355340712512\n",
      "train loss:1.7150796859122446\n",
      "=== epoch:260, train acc:0.6133333333333333, test acc:0.5052 ===\n",
      "train loss:1.5191886434855957\n",
      "train loss:1.489910332270739\n",
      "train loss:1.489881703885387\n",
      "=== epoch:261, train acc:0.6133333333333333, test acc:0.507 ===\n",
      "train loss:1.5640853179383252\n",
      "train loss:1.6297575526595103\n",
      "train loss:1.591458081740571\n",
      "=== epoch:262, train acc:0.6066666666666667, test acc:0.5039 ===\n",
      "train loss:1.504906938411924\n",
      "train loss:1.4692003760350234\n",
      "train loss:1.5874724739590496\n",
      "=== epoch:263, train acc:0.6166666666666667, test acc:0.5116 ===\n",
      "train loss:1.6051172480163398\n",
      "train loss:1.633864613095302\n",
      "train loss:1.5511702683601019\n",
      "=== epoch:264, train acc:0.62, test acc:0.5103 ===\n",
      "train loss:1.644796606898479\n",
      "train loss:1.2494991390537442\n",
      "train loss:1.665274725551404\n",
      "=== epoch:265, train acc:0.6133333333333333, test acc:0.5132 ===\n",
      "train loss:1.5433311123348077\n",
      "train loss:1.6407488290768568\n",
      "train loss:1.511045194246235\n",
      "=== epoch:266, train acc:0.6166666666666667, test acc:0.5134 ===\n",
      "train loss:1.571985652749313\n",
      "train loss:1.438852837217445\n",
      "train loss:1.3943873178911301\n",
      "=== epoch:267, train acc:0.6166666666666667, test acc:0.5155 ===\n",
      "train loss:1.6526549854321462\n",
      "train loss:1.4431997232244926\n",
      "train loss:1.4457876291238694\n",
      "=== epoch:268, train acc:0.6133333333333333, test acc:0.5154 ===\n",
      "train loss:1.5980160521852576\n",
      "train loss:1.5120466059877635\n",
      "train loss:1.4842605164360456\n",
      "=== epoch:269, train acc:0.62, test acc:0.5229 ===\n",
      "train loss:1.368370977341164\n",
      "train loss:1.6357218150710942\n",
      "train loss:1.4697872996801575\n",
      "=== epoch:270, train acc:0.6166666666666667, test acc:0.5194 ===\n",
      "train loss:1.567186892955128\n",
      "train loss:1.5386951808110303\n",
      "train loss:1.517257456528928\n",
      "=== epoch:271, train acc:0.6133333333333333, test acc:0.5179 ===\n",
      "train loss:1.6150065763603088\n",
      "train loss:1.5158809391662251\n",
      "train loss:1.4371031948436062\n",
      "=== epoch:272, train acc:0.6133333333333333, test acc:0.5211 ===\n",
      "train loss:1.2777380947344337\n",
      "train loss:1.696110652034439\n",
      "train loss:1.4931374946352574\n",
      "=== epoch:273, train acc:0.6133333333333333, test acc:0.5203 ===\n",
      "train loss:1.5435381809113253\n",
      "train loss:1.4886700875637757\n",
      "train loss:1.4819115625023846\n",
      "=== epoch:274, train acc:0.6133333333333333, test acc:0.5193 ===\n",
      "train loss:1.5658603875530637\n",
      "train loss:1.6819639031688312\n",
      "train loss:1.5542853692113223\n",
      "=== epoch:275, train acc:0.6166666666666667, test acc:0.5228 ===\n",
      "train loss:1.6229841641004166\n",
      "train loss:1.593402130816783\n",
      "train loss:1.4318566588677888\n",
      "=== epoch:276, train acc:0.6266666666666667, test acc:0.527 ===\n",
      "train loss:1.487775855685753\n",
      "train loss:1.539797199747223\n",
      "train loss:1.5410664353386858\n",
      "=== epoch:277, train acc:0.6266666666666667, test acc:0.5299 ===\n",
      "train loss:1.5399443121583594\n",
      "train loss:1.3950638404374418\n",
      "train loss:1.330520981754878\n",
      "=== epoch:278, train acc:0.6233333333333333, test acc:0.5264 ===\n",
      "train loss:1.5222634231610563\n",
      "train loss:1.4856517792581028\n",
      "train loss:1.5783391279477854\n",
      "=== epoch:279, train acc:0.6266666666666667, test acc:0.5282 ===\n",
      "train loss:1.4212074313609122\n",
      "train loss:1.4479494309135976\n",
      "train loss:1.4909017537424112\n",
      "=== epoch:280, train acc:0.6333333333333333, test acc:0.5318 ===\n",
      "train loss:1.5123032689669977\n",
      "train loss:1.4630883230731675\n",
      "train loss:1.5228844735554459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:281, train acc:0.63, test acc:0.5333 ===\n",
      "train loss:1.458185727380116\n",
      "train loss:1.4969251274056063\n",
      "train loss:1.4368514837974617\n",
      "=== epoch:282, train acc:0.63, test acc:0.5346 ===\n",
      "train loss:1.5733331223908558\n",
      "train loss:1.4226443155328625\n",
      "train loss:1.3149764933136574\n",
      "=== epoch:283, train acc:0.6333333333333333, test acc:0.5316 ===\n",
      "train loss:1.5201069192245236\n",
      "train loss:1.4130023133046001\n",
      "train loss:1.673292414023827\n",
      "=== epoch:284, train acc:0.6366666666666667, test acc:0.5348 ===\n",
      "train loss:1.4948282760793379\n",
      "train loss:1.3426970491182018\n",
      "train loss:1.4857058094079676\n",
      "=== epoch:285, train acc:0.6333333333333333, test acc:0.5354 ===\n",
      "train loss:1.56707468592227\n",
      "train loss:1.5027671344971096\n",
      "train loss:1.4482886498037106\n",
      "=== epoch:286, train acc:0.6366666666666667, test acc:0.5316 ===\n",
      "train loss:1.3246138541291421\n",
      "train loss:1.3706325695770554\n",
      "train loss:1.4555684717100985\n",
      "=== epoch:287, train acc:0.6333333333333333, test acc:0.5297 ===\n",
      "train loss:1.4529895858544128\n",
      "train loss:1.4682366556314037\n",
      "train loss:1.4937060431398086\n",
      "=== epoch:288, train acc:0.6366666666666667, test acc:0.5327 ===\n",
      "train loss:1.3378768292847243\n",
      "train loss:1.395824793305602\n",
      "train loss:1.5178267384589008\n",
      "=== epoch:289, train acc:0.63, test acc:0.5298 ===\n",
      "train loss:1.5883634338773547\n",
      "train loss:1.4969673206463896\n",
      "train loss:1.432300152286046\n",
      "=== epoch:290, train acc:0.63, test acc:0.5376 ===\n",
      "train loss:1.5337198259183602\n",
      "train loss:1.5718201702159897\n",
      "train loss:1.5037051916904625\n",
      "=== epoch:291, train acc:0.6333333333333333, test acc:0.5395 ===\n",
      "train loss:1.4461505772131082\n",
      "train loss:1.363972947786017\n",
      "train loss:1.272150632341973\n",
      "=== epoch:292, train acc:0.6366666666666667, test acc:0.5358 ===\n",
      "train loss:1.3820179762499398\n",
      "train loss:1.3818707878431917\n",
      "train loss:1.3702649230584072\n",
      "=== epoch:293, train acc:0.6333333333333333, test acc:0.5395 ===\n",
      "train loss:1.3535357614989727\n",
      "train loss:1.3208654793522814\n",
      "train loss:1.3911630179016938\n",
      "=== epoch:294, train acc:0.63, test acc:0.5373 ===\n",
      "train loss:1.2803806208173898\n",
      "train loss:1.5056786215272708\n",
      "train loss:1.2973923839439214\n",
      "=== epoch:295, train acc:0.6333333333333333, test acc:0.5389 ===\n",
      "train loss:1.4754450672672967\n",
      "train loss:1.5405814355984762\n",
      "train loss:1.393374603623871\n",
      "=== epoch:296, train acc:0.64, test acc:0.5437 ===\n",
      "train loss:1.371126035202947\n",
      "train loss:1.3517116718444917\n",
      "train loss:1.485484237293263\n",
      "=== epoch:297, train acc:0.64, test acc:0.5401 ===\n",
      "train loss:1.5292031757311733\n",
      "train loss:1.4317406967246626\n",
      "train loss:1.4169128710356573\n",
      "=== epoch:298, train acc:0.6366666666666667, test acc:0.5416 ===\n",
      "train loss:1.5088926963693046\n",
      "train loss:1.3951384375287932\n",
      "train loss:1.474477805791612\n",
      "=== epoch:299, train acc:0.64, test acc:0.5479 ===\n",
      "train loss:1.2767648112528447\n",
      "train loss:1.3510479660907513\n",
      "train loss:1.3476252275930285\n",
      "=== epoch:300, train acc:0.64, test acc:0.5497 ===\n",
      "train loss:1.3152243910397479\n",
      "train loss:1.2025261986298703\n",
      "train loss:1.3625887793261637\n",
      "=== epoch:301, train acc:0.6366666666666667, test acc:0.5482 ===\n",
      "train loss:1.348522134012296\n",
      "train loss:1.450118933128322\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.5504\n"
     ]
    }
   ],
   "source": [
    "network = MultiLayerNetExtend(input_size=784,\n",
    "                              hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
    "                              output_size=10, use_dropout=use_dropout,\n",
    "                              dropout_ration=dropout_ratio)\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=301, mini_batch_size=100,\n",
    "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b268f4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
